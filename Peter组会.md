# 第一次
1.

### 工作流


### 输入：文字/图片/限制参数
	图片：草图/概念图
	限制参数：标高/尺度/地理位置/

输入平面图，转化为效果图

diffusion做概念演变 GAN做概念嵌入


封面
项目背景介绍
	图片生成现状分析
		Diffusion
		GAN
	景观工作流介绍（简单介绍）痛点问题
项目目标/功能介绍
项目timeline
疑问


项目背景（介绍景观工作流+痛点）
项目目标（解决痛点）
项目实现过程（1.生成式图片，当前生成式图片的问题总结）
项目提升点
项目难点


workflow
preliminary analysis

生成图像与现实尺度相关联 增加出图可行性 （像素-》现实）比例尺


"In the field of landscape design, understanding the workflow is crucial. Upon receiving a project, the first step involves a preliminary analysis, which includes location, surrounding environment, and pedestrian flow. The second step is the conceptual design phase, where we seek intention diagrams and sketch plans that combine the client's needs with conceptual elements. The third step, the scheme deepening stage, involves refining various landscape nodes and adding details, textures, and more to establish models for review. The final step is the construction drawing stage, where we create detailed drawings to ensure a smooth construction process.

However, the current workflow has its challenges. The process of finding intention diagrams in the second stage can be time-consuming, and the need for a realistic reference can limit creativity. Furthermore, as client needs may change during the design process, there can be numerous iterations between the second and third steps. Each revision brings a significant workload, leading to fatigue and a mechanical approach to work among designers. Consequently, many designers spend most of their time on these two stages, hindering the exploration of creativity.

The advent of AIGC image generation offers potential solutions to these issues. The current mainstream generation models are primarily based on Diffusion models or GANs. The Diffusion model consists of two steps: the forward process, which gradually adds noise to the original image, and the reverse process, a denoising process that requires gradual denoising. This makes the denoising process resource-intensive. On the other hand, GANs comprise a generator, which creates new data samples, and a discriminator, which distinguishes between the generator's samples and real training samples. Notably, the most popular text-to-image applications currently on the market, midjourney and stable diffusion, are both fundamentally based on diffusion.

Consider a set of images generated by the generative model. The text prompt above the images demonstrates the impressive results of the generated images, explaining why generative models excel in the comics and 2D fields. However, current generative models struggle to be effectively applied in grounded projects, primarily due to their poor control over realistic scales.

The initial goal of this project is to leverage generative models to address the pain points in the landscape design workflow. By automating the tedious and repetitive parts in the second and third steps with AI, we aim to free up designers' time, allowing them to devote more time to creative thinking.

The project framework can be divided into four simple parts. The pre-control stage involves inputting text prompts, landscape project topographic maps, realistic scales, geographical locations, and other parameters. This is followed by generating a batch of landscape plans or intention diagrams. We then select the most satisfactory images for further adjustments, and finally, generate project design drawings that can be implemented.

So, how should I implement this project? Firstly, as there are currently few or no datasets in the landscape field, I need to create my own. In terms of the generator, I plan to explore three approaches: fine-tuning based on stable diffusion, using GAN, and a fusion of stable diffusion and GAN. The effectiveness of each method will be determined through experimentation. For the conditional control part, I plan to use controlNet for pre-control and learn the latest dragGAN to design a new re-control part specifically for this project.

The innovation of this project lies in its ability to generate usable landscape plans based on AI generative models. Additionally, it introduces a realistic scale to the generative model, facilitating a better connection with industrial production. Lastly, it aims to transform the existing workflow in the design field."